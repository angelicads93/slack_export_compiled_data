{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dab1e9-2dc8-4259-8b9c-3b7c0ae8e4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "exportname = \"3d-art-blender-landmarks\"        #Insert the Channel Name here\n",
    "working_directory = os.getcwd()\n",
    "#slackexport_folder_path = f\"{working_directory}/{exportname}\"\n",
    "slackexport_folder_path = \"/home/agds/Documents/RebeccaEverleneTrust/RebeccaEverlene_Slack_export\"  #Insert path where the local copy of the GoogleDrive folder is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb85b63-948e-49d5-abc6-a738a4794a92",
   "metadata": {},
   "source": [
    "# 1. Retrieving all information from Slack's channels and users:\n",
    "\n",
    "The code presented in this section was developed by Rutvikk Kharod (https://github.com/Rutvikk-Khar/Data-Handling-of-Slack-JSON-Exports). There are minor modifications with respect to the original version, mainly to include some extra information in the dataframes and the further csv files.\n",
    "\n",
    "If you are running this code for the first time, go ahead an execute the cells in sections 1.1, 1.2 and 1.3. to extract all the information contained in the exported file \"RebeccaEverlene_Slack_export\". On the other hand, if you have already ran this code, and have the csv files with all the Slack messages and users, then you can skip to Section 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae8a417-b4a3-485e-9902-b0e14ffa0d0a",
   "metadata": {},
   "source": [
    "## 1.1. Slack channels:\n",
    "Reads the json file \"channels.json\", transfers the general information of each Slack channel to a dataframe and writes it to the \"all_channels.csv\" file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef29e36-95a6-4c3e-960c-fc24ed76c78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_path = f\"{slackexport_folder_path}/channels.json\"\n",
    "with open(channels_path, encoding='utf-8') as f:\n",
    "    channels_json = json.load(f)\n",
    "\n",
    "channel_list = pd.DataFrame(columns=[\"ch_id\", \"name\", \"created\", \"creator\", \"is_archived\",\n",
    "                                     \"is_general\", \"members\", \"topic\", \"purpose\"])\n",
    "\n",
    "for channel in range(len(channels_json)):\n",
    "    channel_list.at[channel, \"ch_id\"] = channels_json[channel]['id']\n",
    "    channel_list.at[channel, \"name\"] = channels_json[channel]['name']\n",
    "    channel_list.at[channel, \"created\"] = channels_json[channel]['created']\n",
    "    channel_list.at[channel, \"creator\"] = channels_json[channel]['creator']\n",
    "    channel_list.at[channel, \"is_archived\"] = channels_json[channel]['is_archived']\n",
    "    channel_list.at[channel, \"is_general\"] = channels_json[channel]['is_general']\n",
    "    memberlist = \", \".join(channels_json[channel]['members'])\n",
    "    channel_list.at[channel, \"members\"] = memberlist\n",
    "    channel_list.at[channel, \"topic\"] = channels_json[channel]['topic']['value']\n",
    "    channel_list.at[channel, \"purpose\"] = channels_json[channel]['purpose']['value']\n",
    "\n",
    "    channel_folder_path = f\"{slackexport_folder_path}/{channel_list.at[channel, 'name']}\"\n",
    "    channels_json[channel]['dayslist'] = os.listdir(channel_folder_path)\n",
    "\n",
    "slack_export_channel_filename = \"all_channels.csv\"\n",
    "channel_list.to_csv(slack_export_channel_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569e5983-9b6b-436f-bede-724d4ba8d89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326d7eef-0525-4ca5-bc11-5af1179d1670",
   "metadata": {},
   "source": [
    "## 1.2. Slack messages:\n",
    "Collects all the messages in \"RebeccaEverlene_Slack_export\", stores them on the data frame \"all_messages_df\" and writes it into the file \"all_channels_{Begin_Date}_{End_Date}.csv\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975d32b9-5345-4def-91e3-b9cfa606b431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slack_json_to_dataframe(slack_json):\n",
    "    messages_df = pd.DataFrame(columns=[\"msg_id\", \"ts\", \"user\", \"type\", \"text\", \"reply_count\",\n",
    "                                         \"reply_users_count\", \"ts_latest_reply\", \"ts_thread\", \n",
    "                                         \"parent_user_id\"])\n",
    "    for message in range(len(slack_json)):\n",
    "        if 'files' in slack_json[message] and slack_json[message]['files']:\n",
    "            messages_df.at[message, \"msg_id\"] = slack_json[message]['files'][0]['id']\n",
    "        elif 'client_msg_id' in slack_json[message]:\n",
    "            messages_df.at[message, \"msg_id\"] = slack_json[message]['client_msg_id']\n",
    "        if 'ts' in slack_json[message]:\n",
    "            messages_df.at[message, \"ts\"] = slack_json[message]['ts']\n",
    "        else:\n",
    "            messages_df.at[message, \"ts\"] = None\n",
    "        messages_df.at[message, \"user\"] = slack_json[message].get('user', None)\n",
    "        if 'type' in slack_json[message]:\n",
    "            messages_df.at[message, \"type\"] = slack_json[message]['type']\n",
    "        else:\n",
    "            messages_df.at[message, \"type\"] = None\n",
    "        \n",
    "        if 'text' in slack_json[message]:\n",
    "            messages_df.at[message, \"text\"] = slack_json[message]['text']\n",
    "        else:\n",
    "            messages_df.at[message, \"text\"] = None\n",
    "        if 'reply_count' in slack_json[message]:\n",
    "            messages_df.at[message, \"reply_count\"] = slack_json[message]['reply_count']\n",
    "            messages_df.at[message, \"reply_users_count\"] = slack_json[message]['reply_users_count']\n",
    "            messages_df.at[message, \"ts_latest_reply\"] = slack_json[message]['latest_reply']\n",
    "        if 'parent_user_id' in slack_json[message]:\n",
    "            messages_df.at[message, \"ts_thread\"] = slack_json[message]['thread_ts']\n",
    "            messages_df.at[message, \"parent_user_id\"] = slack_json[message]['parent_user_id']\n",
    "    return messages_df\n",
    "\n",
    "all_messages_df = pd.DataFrame(columns=[\"msg_id\", \"ts\", \"user\", \"type\", \"text\",\n",
    "                                                  \"reply_count\", \"reply_users_count\", \n",
    "                                                  \"ts_latest_reply\", \"ts_thread\", \"parent_user_id\", \n",
    "                                                  \"channel\", \"json_name\", \"json_mod_date\"])\n",
    "\n",
    "for channel in range(len(channels_json)):\n",
    "    all_channel_files_df = pd.DataFrame(columns=[\"msg_id\", \"ts\", \"user\", \"type\", \"text\",\n",
    "                                                 \"reply_count\", \"reply_users_count\", \n",
    "                                                 \"ts_latest_reply\", \"ts_thread\", \"parent_user_id\", \"json_name\", \"json_mod_date\"])\n",
    "\n",
    "    for file_day in range(len(channels_json[channel]['dayslist'])):\n",
    "        parentfolder_path = f\"{slackexport_folder_path}/{channels_json[channel]['name']}\"\n",
    "        filejson_path = f\"{parentfolder_path}/{channels_json[channel]['dayslist'][file_day]}\"\n",
    "        #print(channels_json[channel]['name'], channels_json[channel]['dayslist'][file_day] )\n",
    "        with open(filejson_path, encoding='utf-8') as f:\n",
    "            import_file_json = json.load(f)\n",
    "        import_file_df = slack_json_to_dataframe(import_file_json)\n",
    "        import_file_df['json_name'] = channels_json[channel]['dayslist'][file_day]#[:-5]\n",
    "        import_file_df['json_mod_date'] = datetime.fromtimestamp( os.path.getmtime(filejson_path) )\n",
    "        #print(channels_json[channel]['dayslist'][file_day], datetime.fromtimestamp( os.path.getmtime(filejson_path) ))\n",
    "        all_channel_files_df = pd.concat([all_channel_files_df, import_file_df], ignore_index=True)\n",
    "\n",
    "    all_channel_files_df['channel'] = channels_json[channel]['name']\n",
    "    #all_channel_files_df['file_name'] = \n",
    "    all_messages_df = pd.concat([all_messages_df, all_channel_files_df], ignore_index=True)\n",
    "\n",
    "### To write a .csv file with all the channels:\n",
    "all_messages_mindate = pd.to_datetime(all_messages_df['ts'], unit='s').min().date()\n",
    "all_messages_maxdate = pd.to_datetime(all_messages_df['ts'], unit='s').max().date()\n",
    "all_messages_filename = f\"{\"all_channels\"}_{all_messages_mindate}_to_{all_messages_maxdate}.csv\"  \n",
    "all_messages_df.to_csv(all_messages_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dee6153-3b03-4165-994b-c32a6bc10df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_messages_df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd3c5c8-5a1c-41bc-aaf2-c7da94e017dd",
   "metadata": {},
   "source": [
    "## 1.3. Slack users:\n",
    "Reads the json file \"users.json\", transfers the general information of each Slack user to a dataframe and writes it to the \"all_users.csv\" file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470cc341-8fa8-40c0-b880-478971f188f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_path = f\"{slackexport_folder_path}/users.json\"\n",
    "with open(users_path, encoding='utf-8') as f:\n",
    "    users_json = json.load(f)\n",
    "\n",
    "user_list_df = pd.DataFrame(columns=[\"user_id\", \"team_id\", \"name\", \"deleted\", \"real_name\",\n",
    "                                      \"tz\", \"tz_label\", \"tz_offset\", \"title\", \"display_name\", \n",
    "                                      \"is_bot\"])\n",
    "\n",
    "for user in range(len(users_json)):\n",
    "    user_list_df.at[user, \"user_id\"] = users_json[user]['id']\n",
    "    user_list_df.at[user, \"team_id\"] = users_json[user]['team_id']\n",
    "    user_list_df.at[user, \"name\"] = users_json[user]['name']\n",
    "    user_list_df.at[user, \"deleted\"] = users_json[user]['deleted']\n",
    "    user_list_df.at[user, \"real_name\"] = users_json[user].get('real_name', None)\n",
    "    user_list_df.at[user, \"title\"] = users_json[user]['profile']['title']\n",
    "    user_list_df.at[user, \"display_name\"] = users_json[user]['profile']['display_name']\n",
    "    user_list_df.at[user, \"is_bot\"] = users_json[user]['is_bot']\n",
    "    user_list_df.at[user, \"tz\"] = users_json[user].get('tz', None)\n",
    "    user_list_df.at[user, \"tz_label\"] = users_json[user].get('tz_label', None)\n",
    "    user_list_df.at[user, \"tz_offset\"] = users_json[user].get('tz_offset', None)\n",
    "\n",
    "slack_export_user_filename = \"all_users.csv\"\n",
    "user_list_df.to_csv(slack_export_user_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaab5800-1ed5-4fdb-a2c3-d4b78b7f180a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_list_df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34279637-37ac-4220-811d-16a055f48c87",
   "metadata": {},
   "source": [
    "# 2. Compiling information for a given Slack channel:\n",
    "The three csv files created above contain all the information for all the Slack users and channels. They can be generated once and used as many times as needed for more especialize queries. \n",
    "\n",
    "If you already have the general .csv files saved in your working directory, you can import them into dataframes by executing the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41077998-e7af-4752-9441-a67ba55a35f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_messages_df = pd.read_csv(f\"{working_directory}/all_channels_2021-04-30_to_2024-10-03.csv\")    \n",
    "user_list_df    = pd.read_csv(f\"{working_directory}/all_users.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9e5c32-0060-4b53-a8f9-aad377f55d2f",
   "metadata": {},
   "source": [
    "Otherwise, continue with the cells below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd642ba-1d99-4216-979d-62b2fa7d4e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write a .csv file with the same format as all_channels_2021-04-30_to_2024-10-03.csv but only containing the messages of the \n",
    "### desire channel:\n",
    "exportChannel_messages_df = all_messages_df[all_messages_df['channel']==exportname]\n",
    "exportChannel_mindate = pd.to_datetime(exportChannel_messages_df['ts'], unit='s').min().date()\n",
    "exportChannel_maxdate = pd.to_datetime(exportChannel_messages_df['ts'], unit='s').max().date()\n",
    "exportChannel_messages_filename = f\"{exportname}_{exportChannel_mindate}_to_{exportChannel_maxdate}.csv\"\n",
    "exportChannel_messages_df.to_csv(exportChannel_messages_filename, index=False)\n",
    "\n",
    "#### Create a curated dataframe with the users information from the desired channel:\n",
    "channel_users = []\n",
    "for user in exportChannel_messages_df['user'].unique():\n",
    "    ## Get information from the users dataframe:\n",
    "    if user == \"USLACKBOT\":\n",
    "        user_id = \"Slackbot\"\n",
    "        team_id = ''\n",
    "        name = \"Slackbot\"\n",
    "        display_name = \"Slackbot\"\n",
    "    else:\n",
    "        user_df = user_list_df[user_list_df['user_id']==user][['user_id','team_id','name', 'display_name']]\n",
    "        user_id = user_df['user_id'].values\n",
    "        team_id = user_df['team_id'].values\n",
    "        name = user_df['name'].values\n",
    "        display_name = user_df['display_name'].values\n",
    "\n",
    "    channel_users.append( np.array([user_id, team_id, name, display_name]).flatten() ) \n",
    "channel_users = pd.DataFrame(channel_users, columns=['user_id', 'team_id', 'name', 'display_name'])\n",
    "\n",
    "### Use the curated channel_users dataframe to fill-in the user's information for each message:\n",
    "for index in exportChannel_messages_df.index.values:\n",
    "    #exportChannel_messages_df.at[index, 'user_id'] = channel_users[channel_users['user_id']==exportChannel_messages_df.loc[index]['user']]['user_id'].values\n",
    "    #exportChannel_messages_df.at[index, 'team_id'] = channel_users[channel_users['user_id']==exportChannel_messages_df.loc[index]['user']]['team_id'].values\n",
    "    exportChannel_messages_df.at[index, 'name'] = channel_users[channel_users['user_id']==exportChannel_messages_df.loc[index]['user']]['name'].values\n",
    "    exportChannel_messages_df.at[index, 'display_name'] = channel_users[channel_users['user_id']==exportChannel_messages_df.loc[index]['user']]['display_name'].values\n",
    "\n",
    "exportChannel_messages_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3527bbe-ed5b-4932-8ba5-02da41ac7312",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop unnecessary columns:\n",
    "exportChannel_messages_df.drop(['reply_count', 'reply_users_count', 'ts_latest_reply', 'ts_thread', 'parent_user_id'], axis=1, inplace=True)\n",
    "exportChannel_messages_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17444ad2-45e0-4221-a0cb-bfd0daa2b35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reorder the columns:\n",
    "exportChannel_messages_df = exportChannel_messages_df[['channel', 'json_name', 'json_mod_date', 'user', 'name', 'display_name', 'ts', 'msg_id', 'type', 'text']]\n",
    "exportChannel_messages_df.index = ['']*len(exportChannel_messages_df)\n",
    "exportChannel_messages_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a439b4d-07b3-4cc4-9f2f-f65a0e31db11",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Change format of the time in seconds to a date:\n",
    "exportChannel_messages_df['ts'] = pd.to_datetime(exportChannel_messages_df['ts'], unit='s')\n",
    "exportChannel_messages_df.rename(columns={\"ts\": \"msg_date\"}, inplace=True)\n",
    "exportChannel_messages_df.sort_values(by='msg_date', inplace=True)\n",
    "exportChannel_messages_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab5d24b-641d-41bd-93c5-4f964eb0a013",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write .csv file:\n",
    "cleanExportChannel_filename = f\"{exportname}_{exportChannel_mindate}_to_{exportChannel_maxdate}_compiled.csv\"\n",
    "exportChannel_messages_df.to_csv(cleanExportChannel_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4d50f8-2a15-47ac-a580-4e6751d73842",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
